
// @ts-nocheck

import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'
import { corsHeaders } from '../_shared/cors.ts'

const supabase = createClient(
  Deno.env.get('SUPABASE_URL') ?? '',
  Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? ''
)


serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    console.log('Generate test cases function called');
    const startTime = Date.now();

    // Get user from auth
    const authHeader = req.headers.get('Authorization');
    if (!authHeader) {
      return new Response(
        JSON.stringify({ error: 'Authorization header missing' }),
        { status: 401, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }
    const token = authHeader.replace('Bearer ', '');
    const { data: { user }, error: authError } = await supabase.auth.getUser(token);

    if (authError || !user) {
      console.error('Auth error:', authError);
      return new Response(
        JSON.stringify({ error: 'Unauthorized' }),
        { status: 401, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    const body = await req.json();
    const { story, azureConfig, customPrompt, imageData, useLearnedPatterns } = body;

    // Input validation
    if (!story || !story.title) {
      return new Response(
        JSON.stringify({ error: 'Story data with title is required' }),
        { status: 400, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    // Validate story title length
    if (story.title.length > 255) {
      return new Response(
        JSON.stringify({ error: 'Story title exceeds maximum length of 255 characters' }),
        { status: 400, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    // Truncate description if too long for optimal AI processing
    if (story.description && story.description.length > 5000) {
      console.log(`Truncating long description from ${story.description.length} to 5000 characters`);
      story.description = story.description.substring(0, 5000) + '... [truncated]';
    }

    // Validate Azure OpenAI config
    if (!azureConfig || !azureConfig.endpoint || !azureConfig.apiKey || !azureConfig.deploymentId) {
      return new Response(
        JSON.stringify({ error: 'Azure OpenAI configuration is required (endpoint, apiKey, deploymentId)' }),
        { status: 400, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    // Fetch learned patterns from qa_embeddings if enabled
    let learnedPatternsContext = '';
    if (useLearnedPatterns && story.project_id) {
      console.log('Fetching learned patterns for project:', story.project_id);
      try {
        // Fetch approved embeddings for test cases from this project
        const { data: patterns, error: patternsError } = await supabase
          .from('qa_embeddings')
          .select('content, metadata, artifact_type')
          .eq('project_id', story.project_id)
          .eq('artifact_type', 'test_case')
          .eq('is_approved', true)
          .order('approval_count', { ascending: false })
          .limit(5);

        if (patternsError) {
          console.error('Error fetching patterns:', patternsError);
        } else if (patterns && patterns.length > 0) {
          console.log(`Found ${patterns.length} approved patterns`);
          learnedPatternsContext = `
**LEARNED PATTERNS FROM APPROVED TEST CASES:**
The following are examples of high-quality test cases that have been approved for this project. Use these as reference for style, structure, and coverage:

${patterns.map((p, i) => `--- Pattern ${i + 1} ---
${p.content}
`).join('\n')}

Please follow a similar style, structure, and level of detail when generating new test cases.
`;
        }

        // Also fetch proven patterns from qa_proven_patterns table
        const { data: provenPatterns, error: provenError } = await supabase
          .from('qa_proven_patterns')
          .select('pattern_name, pattern_content, pattern_type, description, confidence_score')
          .or(`is_global.eq.true,project_ids.cs.{${story.project_id}}`)
          .eq('pattern_type', 'test_case')
          .order('confidence_score', { ascending: false })
          .limit(3);

        if (provenError) {
          console.error('Error fetching proven patterns:', provenError);
        } else if (provenPatterns && provenPatterns.length > 0) {
          console.log(`Found ${provenPatterns.length} proven patterns`);
          learnedPatternsContext += `

**PROVEN QA PATTERNS:**
These are established patterns with high success rates:

${provenPatterns.map((p, i) => `--- ${p.pattern_name} (Confidence: ${(p.confidence_score * 100).toFixed(0)}%) ---
${p.description || ''}
${typeof p.pattern_content === 'object' ? JSON.stringify(p.pattern_content, null, 2) : p.pattern_content}
`).join('\n')}
`;
        }
      } catch (patternError) {
        console.error('Failed to fetch learned patterns:', patternError);
      }
    }

    console.log(`Generating test cases for story: ${story.title}`);

    // Build prompt with custom requirements given HIGHEST priority
    let prompt = '';
    
    // Add learned patterns context first if available
    if (learnedPatternsContext) {
      prompt = learnedPatternsContext + '\n\n';
    }
    
    // If custom prompt is provided, it should be the PRIMARY instruction
    if (customPrompt && customPrompt.trim()) {
      prompt += `**CRITICAL INSTRUCTIONS - YOU MUST FOLLOW THESE REQUIREMENTS:**
${customPrompt.trim()}

The above requirements are MANDATORY and must be the PRIMARY focus when generating test cases.

---

Generate test cases for the following user story while strictly adhering to the custom requirements above:

Title: ${story.title}
Description: ${story.description || 'No description provided'}
Priority: ${story.priority || 'Medium'}
Issue Type: ${story.issueType || 'Story'}`;
    } else {
      prompt += `Generate comprehensive test cases for the following user story:

Title: ${story.title}
Description: ${story.description || 'No description provided'}
Priority: ${story.priority || 'Medium'}
Issue Type: ${story.issueType || 'Story'}`;
    }

    // Add image analysis if provided
    if (imageData && Array.isArray(imageData) && imageData.length > 0) {
      prompt += `

UPLOADED IMAGES CONTEXT:
${imageData.length} image(s) have been provided that show UI elements, mockups, wireframes, or other visual context related to this user story. Please analyze all the images and incorporate any visual elements, user interface components, workflows, or specific scenarios shown in the images when generating test cases.`;
    }

    // Only add default test case types if no custom prompt was provided
    if (!customPrompt || !customPrompt.trim()) {
      prompt += `

Please generate test cases that include:
1. Positive test scenarios
2. Negative test scenarios  
3. Edge cases
4. Boundary conditions
5. User acceptance criteria validation`;

      // Add image-specific test requirements
      if (imageData && Array.isArray(imageData) && imageData.length > 0) {
        prompt += `
6. UI-specific test cases based on the uploaded images
7. Visual validation tests for elements shown in the images
8. User interaction tests for components visible in the images`;
      }
    } else {
      // When custom prompt exists, remind AI to focus on it
      prompt += `

Remember: Focus primarily on the CRITICAL INSTRUCTIONS provided at the beginning. Generate test cases that specifically address those requirements.`;
    }

    prompt += `

Format the response as a JSON array of test case objects with the following structure:
{
  "id": "TC001",
  "title": "Test case title",
  "description": "Detailed test case description",
  "type": "positive|negative|edge|boundary", 
  "priority": "high|medium|low",
  "steps": ["Step 1", "Step 2", "Step 3"],
  "expectedResult": "Expected outcome",
  "testData": "Sample test data, input values, or data sets needed for this test case",
  "category": "functional|ui|integration|performance"
}

CRITICAL: Return ONLY valid JSON. Do NOT use JavaScript expressions like .repeat(), string concatenation, or any code. All values must be literal strings or objects. For long strings, just write a descriptive placeholder like "256 character string" instead of code.

Generate 8-12 test cases covering all important scenarios.`;

    // Build Azure OpenAI endpoint from user config
    const azureEndpoint = `${azureConfig.endpoint}/openai/deployments/${azureConfig.deploymentId}/chat/completions?api-version=${azureConfig.apiVersion}`;
    
    const response = await fetch(azureEndpoint, {
      method: 'POST',
      headers: {
        'api-key': azureConfig.apiKey,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        messages: [
          {
            role: 'system',
            content: 'You are a QA expert who generates comprehensive test cases. When an image is provided, analyze it carefully for UI elements, workflows, and visual components. Return only valid JSON arrays without any markdown formatting or explanations.'
          },
          {
            role: 'user',
            content: imageData && Array.isArray(imageData) && imageData.length > 0 ? [
              {
                type: 'text',
                text: prompt
              },
              ...imageData.map(img => ({
                type: 'image_url',
                image_url: {
                  url: img.data
                }
              }))
            ] : prompt
          }
        ],
        temperature: 0.7,
        max_tokens: 2500,
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('Azure OpenAI API error:', response.status, errorText);
      return new Response(
        JSON.stringify({ error: `Azure OpenAI API error: ${response.status}` }),
        { status: response.status, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    const data = await response.json();
    const content = data.choices[0].message.content;

    // Calculate cost (Azure OpenAI gpt-4o pricing may vary - using standard rates as estimate)
    const promptTokens = data.usage?.prompt_tokens || 0;
    const completionTokens = data.usage?.completion_tokens || 0;
    const totalTokens = data.usage?.total_tokens || 0;
    const cost = (promptTokens * 0.00003 / 1000) + (completionTokens * 0.00006 / 1000); // GPT-4o Azure pricing estimate

    // Log usage to analytics
    try {
      await supabase.from('ai_usage_logs').insert({
        user_id: user.id,
        project_id: story.project_id,
        feature_type: 'test_case_generation',
        tokens_used: totalTokens,
        openai_model: `azure-${azureConfig.deploymentId}`,
        openai_tokens_prompt: promptTokens,
        openai_tokens_completion: completionTokens,
        openai_cost_usd: cost,
        execution_time_ms: Date.now() - startTime,
        success: true
      });
    } catch (logError) {
      console.error('Failed to log AI usage:', logError);
    }

    try {
      // Sanitize the content to remove JavaScript expressions that break JSON parsing
      let sanitizedContent = content;
      
      // Remove JavaScript method calls like "a".repeat(256), "string".slice(0,10), etc.
      sanitizedContent = sanitizedContent.replace(/"[^"]*"\.repeat\(\d+\)/g, '"long repeated string"');
      sanitizedContent = sanitizedContent.replace(/"[^"]*"\.slice\([^)]+\)/g, '"sliced string"');
      sanitizedContent = sanitizedContent.replace(/"[^"]*"\.substring\([^)]+\)/g, '"substring"');
      sanitizedContent = sanitizedContent.replace(/"[^"]*"\s*\+\s*"[^"]*"/g, '"concatenated string"');
      
      // Try to extract JSON array if wrapped in markdown code blocks
      const jsonMatch = sanitizedContent.match(/\[[\s\S]*\]/);
      if (jsonMatch) {
        sanitizedContent = jsonMatch[0];
      }
      
      // Parse the JSON response from OpenAI
      const testCases = JSON.parse(sanitizedContent);
      
      // Add additional metadata
      const enrichedTestCases = testCases.map((testCase: any, index: number) => ({
        ...testCase,
        id: testCase.id || `TC${String(index + 1).padStart(3, '0')}`,
        storyId: story.id,
        storyTitle: story.title,
        generatedAt: new Date().toISOString(),
        source: `Azure OpenAI ${azureConfig.deploymentId}`
      }));

      console.log(`Generated ${enrichedTestCases.length} test cases for story ${story.id}`);

      return new Response(
        JSON.stringify({
          success: true,
          testCases: enrichedTestCases,
          story: story
        }),
        { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );

    } catch (parseError) {
      console.error('Failed to parse OpenAI response as JSON:', parseError);
      console.log('Raw content:', content);
      
      // Log failed usage
      try {
        await supabase.from('ai_usage_logs').insert({
          user_id: user.id,
          project_id: story.project_id,
          feature_type: 'test_case_generation',
          tokens_used: data.usage?.total_tokens || 0,
          openai_model: `azure-${azureConfig.deploymentId}`,
          openai_tokens_prompt: data.usage?.prompt_tokens || 0,
          openai_tokens_completion: data.usage?.completion_tokens || 0,
          openai_cost_usd: ((data.usage?.prompt_tokens || 0) * 0.00015 / 1000) + ((data.usage?.completion_tokens || 0) * 0.0006 / 1000),
          execution_time_ms: Date.now() - startTime,
          success: false
        });
      } catch (logError) {
        console.error('Failed to log AI usage:', logError);
      }
      
      return new Response(
        JSON.stringify({
          error: 'Failed to parse generated test cases',
          details: 'Azure OpenAI response was not valid JSON',
          rawContent: content
        }),
        { status: 500, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

  } catch (error) {
    console.error('Error in generate-test-cases function:', error);
    return new Response(
      JSON.stringify({
        error: 'Failed to generate test cases',
        details: error.message
      }),
      { status: 500, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );
  }
});
